{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Recipe Bot Retrieval Evaluation\n",
    "\n",
    "This notebook walks through building and evaluating a BM25 retrieval system for recipes.\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to build a BM25 retrieval engine\n",
    "- How to evaluate retrieval with Recall@k and MRR\n",
    "- Why some queries work better than others for keyword search\n",
    "\n",
    "Video walkthrough: https://youtu.be/GMShL5iC8aY\n",
    "\n",
    "**Bonus**: [Using AI Assisted Coding to Tackle Homework Problems](https://link.courses.maven.com/c/eJw80M2upCAQBeCngZ0Gil8XLGbja5gCymkTbAyoyX37id2Tu6rUl7OoOqm-ajuXLQeQk554qlfr9OxST8rxHHQWMhpOQTrrrFIgNacdt7Kkgr2H2CrmhP38r-fPQYHerZZCmdP7Xr5-XVsOR6t5hKSzIXKDB2MHnQwNHiQMWhIJQ-C9Q_4K3mmbY1zRC_LZw-Scw9XHKCe_Kot8CyDACimMdFIpNRpjwGaX_JogSeuZFt9_-rjjTe8x1Z1vfVlb3ZePhBlLJ17C6zyPztQfBjOD-TfNYD6wFXwnGgrGzmCmG8szQYAZFIO5_5SC8Xpsr_kq9El5J4ziLWwdMY1rwfPFtPj7VPE54w7wLwAA__8a93gB)\n",
    "\n",
    "![AI Assisted Coding Walkthrough Location](../imgs/AIHwWalkthrough.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from rank_bm25 import BM25Okapi\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Look at Your Data First\n",
    "\n",
    "Before writing any code, **look at your data**.\n",
    "\n",
    "> ðŸ’¡ **What is retrieval?** When a user asks \"quick pasta with tomatoes,\" the system needs to find the right recipe from thousands of options. Retrieval is the \"search\" step that narrows down candidates before the LLM generates a response.\n",
    "\n",
    "We have two files in `reference_files/`:\n",
    "- `processed_recipes.json` - 200 recipes with ingredients, steps, and tags\n",
    "- `synthetic_queries.jsonl` - 200 queries, each linked to a source recipe\n",
    "\n",
    "### Use the HTML Viewer\n",
    "\n",
    "Open `reference_files/query_viewer.html` in your browser and upload the JSONL file. This lets you:\n",
    "- Navigate between queries with arrow keys\n",
    "- See what each query looks like and its source recipe\n",
    "- Understand the evaluation task before coding\n",
    "\n",
    "**Pro tip**: You can vibe-code your own viewer. Try this prompt:\n",
    "\n",
    "> \"Make a self-contained HTML file to view JSONL files. It should let me upload a file, navigate between records, and display all fields nicely.\"\n",
    "\n",
    "This is a useful skill for quickly exploring any dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 recipes\n",
      "Example recipe keys: ['id', 'name', 'description', 'minutes', 'ingredients', 'n_ingredients', 'steps', 'n_steps', 'tags', 'nutrition', 'submitted', 'contributor_id', 'full_text']\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = Path('reference_files')\n",
    "\n",
    "# Load recipes\n",
    "with open(BASE_PATH / 'processed_recipes.json') as f:\n",
    "    recipes = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(recipes)} recipes\")\n",
    "print(f\"Example recipe keys: {list(recipes[0].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 5 cheese crab lasagna with roasted garlic and vegetables\n",
      "Cooking time: 245 minutes\n",
      "Ingredients: ['garlic', 'extra virgin olive oil', 'dry white wine', 'fresh asparagus', 'cooking spray']...\n",
      "Steps: 108 steps\n"
     ]
    }
   ],
   "source": [
    "# Look at one recipe\n",
    "recipe = recipes[0]\n",
    "print(f\"Name: {recipe['name']}\")\n",
    "print(f\"Cooking time: {recipe['minutes']} minutes\")\n",
    "print(f\"Ingredients: {recipe['ingredients'][:5]}...\")  # First 5\n",
    "print(f\"Steps: {len(recipe['steps'])} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 queries\n",
      "Example query keys: ['query', 'salient_fact', 'source_recipe_id', 'source_recipe_name', 'source_recipe_url', 'ingredients', 'cooking_time', 'tags']\n"
     ]
    }
   ],
   "source": [
    "# Load queries (JSONL format - one JSON object per line)\n",
    "queries = []\n",
    "with open(BASE_PATH / 'synthetic_queries.jsonl') as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            queries.append(json.loads(line))\n",
    "\n",
    "print(f\"Loaded {len(queries)} queries\")\n",
    "print(f\"Example query keys: {list(queries[0].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What temperature should I set my oven to and how long do I need to bake this sweet, yeast-based bread for it to turn out fluffy and perfectly cooked?\n",
      "\n",
      "Source recipe: amish friendship bread\n",
      "Source recipe ID: 246125\n",
      "\n",
      "Salient fact (what makes this query answerable):\n",
      "1. **Appliance Settings**: The recipe specifies to \"preheat oven to 325Â°F,\" which is a precise temperature setting necessary for baking the Amish friendship bread.\n",
      "\n",
      "2. **Timing Specifics**: The recipe indicates a baking time of \"1 hour,\" which is crucial for ensuring the bread is cooked properly and...\n"
     ]
    }
   ],
   "source": [
    "# Look at one query\n",
    "q = queries[0]\n",
    "print(f\"Query: {q['query']}\")\n",
    "print(f\"\\nSource recipe: {q['source_recipe_name']}\")\n",
    "print(f\"Source recipe ID: {q['source_recipe_id']}\")\n",
    "print(f\"\\nSalient fact (what makes this query answerable):\\n{q['salient_fact'][:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build BM25 Retriever\n",
    "\n",
    "> ðŸ’¡ **BM25 in plain English**: It's a word-matching algorithm. If your query contains \"chicken\" and \"lemon,\" it finds recipes that mention those words, ranking ones where those terms appear frequently but aren't common across all recipes.\n",
    "\n",
    "BM25 is a keyword-based ranking function. It scores documents based on:\n",
    "- Term frequency (how often query terms appear in doc)\n",
    "- Inverse document frequency (rarer terms matter more)\n",
    "- Document length normalization\n",
    "\n",
    "We need to:\n",
    "1. Create a text representation of each recipe\n",
    "2. Tokenize the text (split into words)\n",
    "3. Build the BM25 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example text (first 300 chars):\n",
      "5 cheese crab lasagna with roasted garlic and vegetables garlic extra virgin olive oil dry white wine fresh asparagus cooking spray garlic salt salt & freshly ground black pepper red bell peppers fresh basil dry lasagna noodles roma tomatoes dried oregano parmesan-romano cheese mix butter sweet onio...\n"
     ]
    }
   ],
   "source": [
    "def recipe_to_text(recipe: Dict) -> str:\n",
    "    \"\"\"Combine recipe fields into searchable text.\"\"\"\n",
    "    parts = [\n",
    "        recipe['name'],\n",
    "        ' '.join(recipe.get('ingredients', [])),\n",
    "        ' '.join(recipe.get('steps', [])),\n",
    "        ' '.join(recipe.get('tags', []))\n",
    "    ]\n",
    "    return ' '.join(parts).lower()\n",
    "\n",
    "# Create corpus\n",
    "corpus_texts = [recipe_to_text(r) for r in recipes]\n",
    "print(f\"Example text (first 300 chars):\\n{corpus_texts[0][:300]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 index built with 200 documents\n"
     ]
    }
   ],
   "source": [
    "# Simple tokenization (split on whitespace)\n",
    "tokenized_corpus = [text.split() for text in corpus_texts]\n",
    "\n",
    "# Build BM25 index\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "print(f\"BM25 index built with {len(tokenized_corpus)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query: str, top_k: int = 5) -> List[Tuple[int, float, str]]:\n",
    "    \"\"\"Retrieve top-k recipes for a query.\n",
    "    \n",
    "    Returns: List of (recipe_index, score, recipe_name)\n",
    "    \"\"\"\n",
    "    tokenized_query = query.lower().split()\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    \n",
    "    # Get top-k indices\n",
    "    top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append((recipes[idx]['id'], scores[idx], recipes[idx]['name']))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: air fryer chicken crispy\n",
      "\n",
      "Top 5 results:\n",
      "  1. 7 layer elote dip (score: 6.75)\n",
      "  2. amazingly juicy grilled lemon chicken (score: 6.19)\n",
      "  3. algerian chicken preserved lemon bourek (score: 5.78)\n",
      "  4. a grape picker s lunch sausages and lentils with thyme and wine (score: 5.57)\n",
      "  5. alton s french onion soup attacked by sandi (score: 5.54)\n"
     ]
    }
   ],
   "source": [
    "# Test it\n",
    "test_query = \"air fryer chicken crispy\"\n",
    "results = retrieve(test_query, top_k=5)\n",
    "\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "print(\"Top 5 results:\")\n",
    "for i, (recipe_id, score, name) in enumerate(results, 1):\n",
    "    print(f\"  {i}. {name} (score: {score:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate Retrieval\n",
    "\n",
    "For each query, we know the \"ground truth\" recipe it came from. We measure:\n",
    "\n",
    "- **Recall@k**: Is the correct recipe in the top k results?\n",
    "- **MRR (Mean Reciprocal Rank)**: Average of 1/rank for correct recipes\n",
    "\n",
    "> ðŸ’¡ **What do these metrics tell us?** Recall@5 of 65% means \"65% of the time, the right recipe is somewhere in the top 5.\" MRR accounts for *where* it ranksâ€”finding it at #1 is better than #5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retrieval(queries: List[Dict], top_k: int = 5) -> Dict:\n",
    "    \"\"\"Evaluate retrieval performance.\"\"\"\n",
    "    recall_at_1 = 0\n",
    "    recall_at_3 = 0\n",
    "    recall_at_5 = 0\n",
    "    reciprocal_ranks = []\n",
    "    \n",
    "    for q in queries:\n",
    "        query_text = q['query']\n",
    "        target_id = q['source_recipe_id']\n",
    "        \n",
    "        results = retrieve(query_text, top_k=top_k)\n",
    "        retrieved_ids = [r[0] for r in results]\n",
    "        \n",
    "        # Check recall at different k\n",
    "        if target_id in retrieved_ids[:1]:\n",
    "            recall_at_1 += 1\n",
    "        if target_id in retrieved_ids[:3]:\n",
    "            recall_at_3 += 1\n",
    "        if target_id in retrieved_ids[:5]:\n",
    "            recall_at_5 += 1\n",
    "        \n",
    "        # Calculate reciprocal rank\n",
    "        if target_id in retrieved_ids:\n",
    "            rank = retrieved_ids.index(target_id) + 1\n",
    "            reciprocal_ranks.append(1.0 / rank)\n",
    "        else:\n",
    "            reciprocal_ranks.append(0.0)\n",
    "    \n",
    "    n = len(queries)\n",
    "    return {\n",
    "        'recall_at_1': recall_at_1 / n,\n",
    "        'recall_at_3': recall_at_3 / n,\n",
    "        'recall_at_5': recall_at_5 / n,\n",
    "        'mrr': sum(reciprocal_ranks) / n,\n",
    "        'total_queries': n\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Performance\n",
      "==============================\n",
      "Recall@1: 40.0%\n",
      "Recall@3: 55.0%\n",
      "Recall@5: 65.0%\n",
      "MRR:      0.488\n",
      "\n",
      "Evaluated on 200 queries\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "results = evaluate_retrieval(queries)\n",
    "\n",
    "print(\"Retrieval Performance\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Recall@1: {results['recall_at_1']:.1%}\")\n",
    "print(f\"Recall@3: {results['recall_at_3']:.1%}\")\n",
    "print(f\"Recall@5: {results['recall_at_5']:.1%}\")\n",
    "print(f\"MRR:      {results['mrr']:.3f}\")\n",
    "print(f\"\\nEvaluated on {results['total_queries']} queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Results\n",
    "\n",
    "Numbers alone don't tell the full story. Let's look at specific successes and failures to understand *why* retrieval works or breaks.\n",
    "\n",
    "> ðŸ’¡ **This is where you build intuition.** Looking at failures reveals specific patterns that give you objective, measurable things to improveâ€”rather than vague feelings that are hard to act on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successes: 130\n",
      "Failures: 70\n"
     ]
    }
   ],
   "source": [
    "# Find examples where retrieval worked and failed\n",
    "successes = []\n",
    "failures = []\n",
    "\n",
    "for q in queries:\n",
    "    results = retrieve(q['query'], top_k=5)\n",
    "    retrieved_ids = [r[0] for r in results]\n",
    "    \n",
    "    if q['source_recipe_id'] in retrieved_ids:\n",
    "        rank = retrieved_ids.index(q['source_recipe_id']) + 1\n",
    "        successes.append({'query': q, 'rank': rank, 'results': results})\n",
    "    else:\n",
    "        failures.append({'query': q, 'results': results})\n",
    "\n",
    "print(f\"Successes: {len(successes)}\")\n",
    "print(f\"Failures: {len(failures)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS EXAMPLE\n",
      "==================================================\n",
      "Query: What temperature should I set my oven to and how long do I need to bake this sweet, yeast-based bread for it to turn out fluffy and perfectly cooked?\n",
      "\n",
      "Target: amish friendship bread\n",
      "Found at rank: 2\n",
      "\n",
      "Top 5 results:\n",
      "    1. 100 whole wheat bread non dense heavy white bread texture\n",
      "  âœ“ 2. amish friendship bread\n",
      "    3. amazing stuffing from scratch breadmaker recommended\n",
      "    4. 10 calorie chocolate miracle noodle cookies\n",
      "    5. 100 whole grain wheat bread\n"
     ]
    }
   ],
   "source": [
    "# Look at a success\n",
    "if successes:\n",
    "    s = successes[0]\n",
    "    print(\"SUCCESS EXAMPLE\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Query: {s['query']['query']}\")\n",
    "    print(f\"\\nTarget: {s['query']['source_recipe_name']}\")\n",
    "    print(f\"Found at rank: {s['rank']}\")\n",
    "    print(f\"\\nTop 5 results:\")\n",
    "    for i, (rid, score, name) in enumerate(s['results'], 1):\n",
    "        marker = \"âœ“\" if rid == s['query']['source_recipe_id'] else \" \"\n",
    "        print(f\"  {marker} {i}. {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILURE EXAMPLE\n",
      "==================================================\n",
      "Query: What's the best way to poach salmon so that it's perfectly cooked and not dry? I heard the timing and temperature are really important, but I'm not sure how long to simmer it or how hot to get the water first.\n",
      "\n",
      "Target: 4th of july salmon with egg sauce\n",
      "\n",
      "Top 5 results (none are correct):\n",
      "  1. 3 step fall off the bone ribs easy\n",
      "  2. amish friendship bread\n",
      "  3. amish cinnamon bread friendship bread\n",
      "  4. 2 hour turkey really\n",
      "  5. the gumbo pages traditional red beans and rice\n",
      "\n",
      "Why it failed: The query terms may not match the recipe text well.\n"
     ]
    }
   ],
   "source": [
    "# Look at a failure\n",
    "if failures:\n",
    "    f = failures[0]\n",
    "    print(\"FAILURE EXAMPLE\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Query: {f['query']['query']}\")\n",
    "    print(f\"\\nTarget: {f['query']['source_recipe_name']}\")\n",
    "    print(f\"\\nTop 5 results (none are correct):\")\n",
    "    for i, (rid, score, name) in enumerate(f['results'], 1):\n",
    "        print(f\"  {i}. {name}\")\n",
    "    print(f\"\\nWhy it failed: The query terms may not match the recipe text well.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optional: Query Rewriting\n",
    "\n",
    "One way to improve retrieval is to rewrite queries to better match recipe text.\n",
    "\n",
    "For example:\n",
    "- \"What temp for crispy chicken?\" â†’ \"chicken crispy temperature degrees oven\"\n",
    "\n",
    "This can be done with an LLM. Here's the concept (not run by default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example rewrite prompt:\n",
      "\n",
      "You are optimizing a cooking query for recipe search. \n",
      "Rewrite the query to include terms that appear in recipe text.\n",
      "\n",
      "Guidelines:\n",
      "- Use specific cooking terms\n",
      "- Include equipment names\n",
      "- Add ingredient names\n",
      "- Remove question words (what, how, when)\n",
      "\n",
      "Original: \"What air fryer settings for frozen chicken?\"\n",
      "Optimized:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Conceptual example - would require LLM API\n",
    "REWRITE_PROMPT = \"\"\"\n",
    "You are optimizing a cooking query for recipe search. \n",
    "Rewrite the query to include terms that appear in recipe text.\n",
    "\n",
    "Guidelines:\n",
    "- Use specific cooking terms\n",
    "- Include equipment names\n",
    "- Add ingredient names\n",
    "- Remove question words (what, how, when)\n",
    "\n",
    "Original: \"{query}\"\n",
    "Optimized:\n",
    "\"\"\"\n",
    "\n",
    "print(\"Example rewrite prompt:\")\n",
    "print(REWRITE_PROMPT.format(query=\"What air fryer settings for frozen chicken?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What we built:**\n",
    "- BM25 retrieval engine for recipes\n",
    "- Evaluation pipeline with Recall@k and MRR\n",
    "\n",
    "**Key insights:**\n",
    "- BM25 works well when query terms match recipe text\n",
    "- Failures often happen when users use different words than recipes\n",
    "- Query rewriting can help bridge this vocabulary gap\n",
    "\n",
    "**Next steps:**\n",
    "- Try different text representations (e.g., just ingredients)\n",
    "- Implement query rewriting with an LLM\n",
    "- Compare BM25 with embedding-based retrieval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recipe-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
